{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLYGsUPASoBg"
   },
   "source": [
    "Kaggle:https://www.kaggle.com/sdolezel/black-friday\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以前やったランダムフォレストでの予測とLightGBMによる予測の違いを見ていきます。<br>\n",
    "モデルを変えた時により精度の向上を図れるのかを見ていきます。<br>\n",
    "LightGBMである理由は、モデルが**ランダムフォレストの上位互換・計算が早い**という理由です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここではパラメータ調整によって、どこまで精度が上がるかという結果を重視していきたいと思う。<br>\n",
    "データに関するアイデアやデータの量が少ないときのテストケースにしていきたい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 1384,
     "status": "ok",
     "timestamp": 1634575188142,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "1Bdc09hAPE3G"
   },
   "outputs": [],
   "source": [
    "# ライブラリのインポート  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "import optuna.integration.lightgbm as lgb_o\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1634575189309,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "GesVVtOTP9NB",
    "outputId": "967b9617-06cb-4186-d83e-e7bef26086fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>City_Category_0</th>\n",
       "      <th>City_Category_1</th>\n",
       "      <th>City_Category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1000001</td>\n",
       "      <td>-1.028774</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.032409</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1000001</td>\n",
       "      <td>0.722139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.629051</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1000001</td>\n",
       "      <td>-0.845799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.259820</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1000001</td>\n",
       "      <td>-0.869157</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.963190</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1000002</td>\n",
       "      <td>1.077382</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.983314</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550063</th>\n",
       "      <td>550063</td>\n",
       "      <td>1006033</td>\n",
       "      <td>1.924156</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.908083</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550064</th>\n",
       "      <td>550064</td>\n",
       "      <td>1006035</td>\n",
       "      <td>1.953267</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.916202</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550065</th>\n",
       "      <td>550065</td>\n",
       "      <td>1006036</td>\n",
       "      <td>1.953267</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.919981</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550066</th>\n",
       "      <td>550066</td>\n",
       "      <td>1006038</td>\n",
       "      <td>1.953267</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.899897</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550067</th>\n",
       "      <td>550067</td>\n",
       "      <td>1006039</td>\n",
       "      <td>1.916360</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.194405</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550068 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  User_ID  Product_ID  Gender  Age  Occupation  \\\n",
       "0                0  1000001   -1.028774       0    0          10   \n",
       "1                1  1000001    0.722139       0    0          10   \n",
       "2                2  1000001   -0.845799       0    0          10   \n",
       "3                3  1000001   -0.869157       0    0          10   \n",
       "4                4  1000002    1.077382       1    6          16   \n",
       "...            ...      ...         ...     ...  ...         ...   \n",
       "550063      550063  1006033    1.924156       1    5          13   \n",
       "550064      550064  1006035    1.953267       0    2           1   \n",
       "550065      550065  1006036    1.953267       0    2          15   \n",
       "550066      550066  1006038    1.953267       0    6           1   \n",
       "550067      550067  1006039    1.916360       0    4           0   \n",
       "\n",
       "        Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                                2               0                   3   \n",
       "1                                2               0                   1   \n",
       "2                                2               0                  12   \n",
       "3                                2               0                  12   \n",
       "4                                4               0                   8   \n",
       "...                            ...             ...                 ...   \n",
       "550063                           1               1                  20   \n",
       "550064                           3               0                  20   \n",
       "550065                           4               1                  20   \n",
       "550066                           2               0                  20   \n",
       "550067                           4               1                  20   \n",
       "\n",
       "        Product_Category_2  Purchase  City_Category_0  City_Category_1  \\\n",
       "0                      9.0  9.032409                1                0   \n",
       "1                      6.0  9.629051                1                0   \n",
       "2                      9.0  7.259820                1                0   \n",
       "3                     14.0  6.963190                1                0   \n",
       "4                      9.0  8.983314                0                0   \n",
       "...                    ...       ...              ...              ...   \n",
       "550063                 9.0  5.908083                0                1   \n",
       "550064                 9.0  5.916202                0                0   \n",
       "550065                 9.0  4.919981                0                1   \n",
       "550066                 9.0  5.899897                0                0   \n",
       "550067                 9.0  6.194405                0                1   \n",
       "\n",
       "        City_Category_2  \n",
       "0                     0  \n",
       "1                     0  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     1  \n",
       "...                 ...  \n",
       "550063                0  \n",
       "550064                1  \n",
       "550065                0  \n",
       "550066                1  \n",
       "550067                0  \n",
       "\n",
       "[550068 rows x 14 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## データセットの読み込み\n",
    "train = pd.read_csv('preprocessed_train.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1634575189309,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "uJPPvX6nTnWy",
    "outputId": "f61bafa5-da5e-441a-8b38-fe9c0326c240"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'User_ID', 'Product_ID', 'Gender', 'Age', 'Occupation',\n",
       "       'Stay_In_Current_City_Years', 'Marital_Status', 'Product_Category_1',\n",
       "       'Product_Category_2', 'Purchase', 'City_Category_0', 'City_Category_1',\n",
       "       'City_Category_2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#カラムの種類\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634575189310,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "0bFtpeFGTsRq",
    "outputId": "02e9f311-2285-4e87-e969-727932b7219c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550068, 14)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データのサイズ\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1634575189310,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "6IxOQvDVTxRa",
    "outputId": "6990a352-9ce0-41d8-c574-2421e250c32e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Purchase</th>\n",
       "      <th>City_Category_0</th>\n",
       "      <th>City_Category_1</th>\n",
       "      <th>City_Category_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>550068.000000</td>\n",
       "      <td>5.500680e+05</td>\n",
       "      <td>5.500680e+05</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "      <td>550068.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>275033.500000</td>\n",
       "      <td>1.003029e+06</td>\n",
       "      <td>-1.196239e-15</td>\n",
       "      <td>0.753105</td>\n",
       "      <td>2.496430</td>\n",
       "      <td>8.076707</td>\n",
       "      <td>1.858418</td>\n",
       "      <td>0.409653</td>\n",
       "      <td>5.404270</td>\n",
       "      <td>9.576434</td>\n",
       "      <td>8.939354</td>\n",
       "      <td>0.268549</td>\n",
       "      <td>0.420263</td>\n",
       "      <td>0.311189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>158791.098273</td>\n",
       "      <td>1.727592e+03</td>\n",
       "      <td>1.000001e+00</td>\n",
       "      <td>0.431205</td>\n",
       "      <td>1.353632</td>\n",
       "      <td>6.522660</td>\n",
       "      <td>1.289443</td>\n",
       "      <td>0.491770</td>\n",
       "      <td>3.936211</td>\n",
       "      <td>4.226025</td>\n",
       "      <td>0.740298</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.493601</td>\n",
       "      <td>0.462980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000001e+06</td>\n",
       "      <td>-1.699357e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.484907</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>137516.750000</td>\n",
       "      <td>1.001516e+06</td>\n",
       "      <td>-7.552848e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.669571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>275033.500000</td>\n",
       "      <td>1.003077e+06</td>\n",
       "      <td>-4.869089e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.993055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>412550.250000</td>\n",
       "      <td>1.004478e+06</td>\n",
       "      <td>8.214124e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>9.397152</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>550067.000000</td>\n",
       "      <td>1.006040e+06</td>\n",
       "      <td>1.953267e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>10.084183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0       User_ID    Product_ID         Gender  \\\n",
       "count  550068.000000  5.500680e+05  5.500680e+05  550068.000000   \n",
       "mean   275033.500000  1.003029e+06 -1.196239e-15       0.753105   \n",
       "std    158791.098273  1.727592e+03  1.000001e+00       0.431205   \n",
       "min         0.000000  1.000001e+06 -1.699357e+00       0.000000   \n",
       "25%    137516.750000  1.001516e+06 -7.552848e-01       1.000000   \n",
       "50%    275033.500000  1.003077e+06 -4.869089e-02       1.000000   \n",
       "75%    412550.250000  1.004478e+06  8.214124e-01       1.000000   \n",
       "max    550067.000000  1.006040e+06  1.953267e+00       1.000000   \n",
       "\n",
       "                 Age     Occupation  Stay_In_Current_City_Years  \\\n",
       "count  550068.000000  550068.000000               550068.000000   \n",
       "mean        2.496430       8.076707                    1.858418   \n",
       "std         1.353632       6.522660                    1.289443   \n",
       "min         0.000000       0.000000                    0.000000   \n",
       "25%         2.000000       2.000000                    1.000000   \n",
       "50%         2.000000       7.000000                    2.000000   \n",
       "75%         3.000000      14.000000                    3.000000   \n",
       "max         6.000000      20.000000                    4.000000   \n",
       "\n",
       "       Marital_Status  Product_Category_1  Product_Category_2       Purchase  \\\n",
       "count   550068.000000       550068.000000       550068.000000  550068.000000   \n",
       "mean         0.409653            5.404270            9.576434       8.939354   \n",
       "std          0.491770            3.936211            4.226025       0.740298   \n",
       "min          0.000000            1.000000            2.000000       2.484907   \n",
       "25%          0.000000            1.000000            8.000000       8.669571   \n",
       "50%          0.000000            5.000000            9.000000       8.993055   \n",
       "75%          1.000000            8.000000           14.000000       9.397152   \n",
       "max          1.000000           20.000000           18.000000      10.084183   \n",
       "\n",
       "       City_Category_0  City_Category_1  City_Category_2  \n",
       "count    550068.000000    550068.000000    550068.000000  \n",
       "mean          0.268549         0.420263         0.311189  \n",
       "std           0.443205         0.493601         0.462980  \n",
       "min           0.000000         0.000000         0.000000  \n",
       "25%           0.000000         0.000000         0.000000  \n",
       "50%           0.000000         0.000000         0.000000  \n",
       "75%           1.000000         1.000000         1.000000  \n",
       "max           1.000000         1.000000         1.000000  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#データの統計情報\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1634575189722,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "4U63lsfBT1Ha",
    "outputId": "5752fd38-b9fe-429e-e2a2-3740fde0f399"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 550068 entries, 0 to 550067\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   Unnamed: 0                  550068 non-null  int64  \n",
      " 1   User_ID                     550068 non-null  int64  \n",
      " 2   Product_ID                  550068 non-null  float64\n",
      " 3   Gender                      550068 non-null  int64  \n",
      " 4   Age                         550068 non-null  int64  \n",
      " 5   Occupation                  550068 non-null  int64  \n",
      " 6   Stay_In_Current_City_Years  550068 non-null  int64  \n",
      " 7   Marital_Status              550068 non-null  int64  \n",
      " 8   Product_Category_1          550068 non-null  int64  \n",
      " 9   Product_Category_2          550068 non-null  float64\n",
      " 10  Purchase                    550068 non-null  float64\n",
      " 11  City_Category_0             550068 non-null  int64  \n",
      " 12  City_Category_1             550068 non-null  int64  \n",
      " 13  City_Category_2             550068 non-null  int64  \n",
      "dtypes: float64(3), int64(11)\n",
      "memory usage: 58.8 MB\n"
     ]
    }
   ],
   "source": [
    "#　データ型、欠損値の確認\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1634575189722,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "gC-t0eAIT7Xq",
    "outputId": "1c13f8ab-e1b1-474f-c908-373e19bf69de"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                    0\n",
       "User_ID                       0\n",
       "Product_ID                    0\n",
       "Gender                        0\n",
       "Age                           0\n",
       "Occupation                    0\n",
       "Stay_In_Current_City_Years    0\n",
       "Marital_Status                0\n",
       "Product_Category_1            0\n",
       "Product_Category_2            0\n",
       "Purchase                      0\n",
       "City_Category_0               0\n",
       "City_Category_1               0\n",
       "City_Category_2               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAy69VVRYH3I"
   },
   "source": [
    "欠損が多いカラムProduct_Category_3は今回は使用せずに分析していく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634575214094,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "QWKPRovNh-oN"
   },
   "outputs": [],
   "source": [
    "# 特徴量と目的変数を分ける\n",
    "X = train.drop(['Purchase',\"Unnamed: 0\"], axis=1)\n",
    "Y = train['Purchase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 305,
     "status": "ok",
     "timestamp": 1634575214395,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "PmOiKI9qiLa5",
    "outputId": "78b8c02d-3480-4413-aac2-6c0601afc0d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(440054, 12) (110014, 12) (440054,) (110014,)\n"
     ]
    }
   ],
   "source": [
    "# 訓練と検証用に分割\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=1234)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634575214396,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "lpfWwiWPit9F"
   },
   "outputs": [],
   "source": [
    "## データを標準化\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1634575214396,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "-LCru7RrlSal",
    "outputId": "c219d7d2-8efa-4a32-cbb8-d92c76b168e4"
   },
   "outputs": [],
   "source": [
    "# LightGBMの検証用にさらに分割\n",
    "X_main,X_valid,y_main,y_valid = train_test_split(X_train,y_train,test_size=0.1,random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOmDXzjhlpHi"
   },
   "source": [
    "## モデル構築"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJQvAHXP7u-Z"
   },
   "source": [
    "モデルによる違いを出すために、3つのモデルで比較。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CiVqR6wpoSUh"
   },
   "source": [
    "### ランダムフォレスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 281208,
     "status": "ok",
     "timestamp": 1634575580069,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "QTKj_FzGnwDr",
    "outputId": "5175b5be-bc1d-47ac-db26-484f916cace1"
   },
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('RF_fix_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 39342,
     "status": "ok",
     "timestamp": 1634575619409,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "wFeDsy_9ojJj"
   },
   "outputs": [],
   "source": [
    "y_predict_train = loaded_model.predict(X_train)\n",
    "y_predict_test = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 39228,
     "status": "ok",
     "timestamp": 1634575658628,
     "user": {
      "displayName": "真保勇佑",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "05954062037845181310"
     },
     "user_tz": -540
    },
    "id": "SPnDDX1Vpk-9",
    "outputId": "c4b41d1c-0ae5-4c99-add6-004d089d305e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train: 0.3741649001973442\n",
      "rmse_test: 0.3787532048289919\n",
      "------------------------------\n",
      "RF Train Score: 0.7448764411274139\n",
      "RF Train Score: 0.7368749580252367\n"
     ]
    }
   ],
   "source": [
    "# モデル評価(RMSEとR2)\n",
    "RMSE_TRAIN = np.sqrt(mean_squared_error(y_train,y_predict_train))\n",
    "RMSE_TEST = np.sqrt(mean_squared_error(y_test,y_predict_test))\n",
    "print('rmse_train:',RMSE_TRAIN)\n",
    "print('rmse_test:',RMSE_TEST)\n",
    "print('-'*30)\n",
    "print('RF Train Score:',loaded_model.score(X_train,y_train))\n",
    "print('RF Train Score:',loaded_model.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当たり前ですが、前回の結果と変わらないものになります。<br>\n",
    "ここからモデルを変えるとどうなるかのベースラインになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l2: 0.452701\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[2]\tvalid_0's l2: 0.392773\n",
      "[3]\tvalid_0's l2: 0.344254\n",
      "[4]\tvalid_0's l2: 0.305015\n",
      "[5]\tvalid_0's l2: 0.273246\n",
      "[6]\tvalid_0's l2: 0.247569\n",
      "[7]\tvalid_0's l2: 0.226753\n",
      "[8]\tvalid_0's l2: 0.209857\n",
      "[9]\tvalid_0's l2: 0.196184\n",
      "[10]\tvalid_0's l2: 0.185038\n",
      "[11]\tvalid_0's l2: 0.176063\n",
      "[12]\tvalid_0's l2: 0.168776\n",
      "[13]\tvalid_0's l2: 0.162838\n",
      "[14]\tvalid_0's l2: 0.158087\n",
      "[15]\tvalid_0's l2: 0.154181\n",
      "[16]\tvalid_0's l2: 0.150832\n",
      "[17]\tvalid_0's l2: 0.148085\n",
      "[18]\tvalid_0's l2: 0.145981\n",
      "[19]\tvalid_0's l2: 0.144241\n",
      "[20]\tvalid_0's l2: 0.142699\n",
      "[21]\tvalid_0's l2: 0.141431\n",
      "[22]\tvalid_0's l2: 0.140554\n",
      "[23]\tvalid_0's l2: 0.139613\n",
      "[24]\tvalid_0's l2: 0.138796\n",
      "[25]\tvalid_0's l2: 0.138138\n",
      "[26]\tvalid_0's l2: 0.13759\n",
      "[27]\tvalid_0's l2: 0.13713\n",
      "[28]\tvalid_0's l2: 0.136639\n",
      "[29]\tvalid_0's l2: 0.136312\n",
      "[30]\tvalid_0's l2: 0.135984\n",
      "[31]\tvalid_0's l2: 0.135595\n",
      "[32]\tvalid_0's l2: 0.13529\n",
      "[33]\tvalid_0's l2: 0.13499\n",
      "[34]\tvalid_0's l2: 0.134754\n",
      "[35]\tvalid_0's l2: 0.134458\n",
      "[36]\tvalid_0's l2: 0.134177\n",
      "[37]\tvalid_0's l2: 0.133936\n",
      "[38]\tvalid_0's l2: 0.133659\n",
      "[39]\tvalid_0's l2: 0.133431\n",
      "[40]\tvalid_0's l2: 0.133213\n",
      "[41]\tvalid_0's l2: 0.133017\n",
      "[42]\tvalid_0's l2: 0.132801\n",
      "[43]\tvalid_0's l2: 0.13259\n",
      "[44]\tvalid_0's l2: 0.132341\n",
      "[45]\tvalid_0's l2: 0.132139\n",
      "[46]\tvalid_0's l2: 0.131899\n",
      "[47]\tvalid_0's l2: 0.131771\n",
      "[48]\tvalid_0's l2: 0.131576\n",
      "[49]\tvalid_0's l2: 0.131396\n",
      "[50]\tvalid_0's l2: 0.131215\n",
      "[51]\tvalid_0's l2: 0.131043\n",
      "[52]\tvalid_0's l2: 0.130906\n",
      "[53]\tvalid_0's l2: 0.130738\n",
      "[54]\tvalid_0's l2: 0.13055\n",
      "[55]\tvalid_0's l2: 0.130355\n",
      "[56]\tvalid_0's l2: 0.130172\n",
      "[57]\tvalid_0's l2: 0.130024\n",
      "[58]\tvalid_0's l2: 0.129842\n",
      "[59]\tvalid_0's l2: 0.129649\n",
      "[60]\tvalid_0's l2: 0.129516\n",
      "[61]\tvalid_0's l2: 0.129292\n",
      "[62]\tvalid_0's l2: 0.129155\n",
      "[63]\tvalid_0's l2: 0.129054\n",
      "[64]\tvalid_0's l2: 0.128953\n",
      "[65]\tvalid_0's l2: 0.128759\n",
      "[66]\tvalid_0's l2: 0.128625\n",
      "[67]\tvalid_0's l2: 0.128503\n",
      "[68]\tvalid_0's l2: 0.128361\n",
      "[69]\tvalid_0's l2: 0.128224\n",
      "[70]\tvalid_0's l2: 0.128133\n",
      "[71]\tvalid_0's l2: 0.127979\n",
      "[72]\tvalid_0's l2: 0.127849\n",
      "[73]\tvalid_0's l2: 0.127781\n",
      "[74]\tvalid_0's l2: 0.127695\n",
      "[75]\tvalid_0's l2: 0.127579\n",
      "[76]\tvalid_0's l2: 0.127502\n",
      "[77]\tvalid_0's l2: 0.127423\n",
      "[78]\tvalid_0's l2: 0.127334\n",
      "[79]\tvalid_0's l2: 0.127203\n",
      "[80]\tvalid_0's l2: 0.127075\n",
      "[81]\tvalid_0's l2: 0.127017\n",
      "[82]\tvalid_0's l2: 0.126933\n",
      "[83]\tvalid_0's l2: 0.126869\n",
      "[84]\tvalid_0's l2: 0.126775\n",
      "[85]\tvalid_0's l2: 0.126679\n",
      "[86]\tvalid_0's l2: 0.126561\n",
      "[87]\tvalid_0's l2: 0.12645\n",
      "[88]\tvalid_0's l2: 0.126415\n",
      "[89]\tvalid_0's l2: 0.126311\n",
      "[90]\tvalid_0's l2: 0.12626\n",
      "[91]\tvalid_0's l2: 0.126177\n",
      "[92]\tvalid_0's l2: 0.126071\n",
      "[93]\tvalid_0's l2: 0.125963\n",
      "[94]\tvalid_0's l2: 0.125917\n",
      "[95]\tvalid_0's l2: 0.125875\n",
      "[96]\tvalid_0's l2: 0.12574\n",
      "[97]\tvalid_0's l2: 0.125675\n",
      "[98]\tvalid_0's l2: 0.125544\n",
      "[99]\tvalid_0's l2: 0.125481\n",
      "[100]\tvalid_0's l2: 0.125414\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's l2: 0.125414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(random_state=123)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBM = lgb.LGBMRegressor(random_state=123)\n",
    "GBM.fit(X_main, y_main,eval_set=(X_valid,y_valid),early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_train_pred = GBM.predict(X_train)\n",
    "gbm_test_pred = GBM.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train: 0.3557383664347441\n",
      "rmse_test: 0.37103728628562715\n",
      "------------------------------\n",
      "GBM Train Score: 0.7693858834629067\n",
      "GBM Train Score: 0.7474864661851452\n"
     ]
    }
   ],
   "source": [
    "# モデル評価(RMSEとR2)\n",
    "GBM_TRAIN = np.sqrt(mean_squared_error(y_train,gbm_train_pred))\n",
    "GBM_TEST = np.sqrt(mean_squared_error(y_test,gbm_test_pred))\n",
    "print('rmse_train:',GBM_TRAIN)\n",
    "print('rmse_test:',GBM_TEST)\n",
    "print('-'*30)\n",
    "print('GBM Train Score:',GBM.score(X_train,y_train))\n",
    "print('GBM Train Score:',GBM.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBMを使うと確かに精度の向上は目込める。<br>\n",
    "これをチューニングしていくことでどれだけボトムアップできるかを狙っていく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optunaでパラメータ探索"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optunaでパラメータ探索を行っていきます。<br>\n",
    "Optunaを使った理由としては、探索がGridSearchに比べて早く、コードも書きやすい点にあります。<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gbm = lgb_o.Dataset(X_main, y_main)\n",
    "val_gbm = lgb_o.Dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベースのパラメータの設定（回帰・評価関数など）\n",
    "params = {'objective': 'regression',\n",
    "          'metric': 'rmse',\n",
    "          'random_seed':0} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-10-21 09:26:38,768]\u001b[0m A new study created in memory with name: no-name-b1594408-b7da-4029-93b0-78577c54f0ca\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.348031\n",
      "[400]\tvalid_0's rmse: 0.340678\n",
      "[600]\tvalid_0's rmse: 0.336594\n",
      "[800]\tvalid_0's rmse: 0.334192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.332675:  14%|#4        | 1/7 [00:04<00:28,  4.79s/it]\u001b[32m[I 2021-10-21 09:26:43,561]\u001b[0m Trial 0 finished with value: 0.33267493933975395 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.33267493933975395.\u001b[0m\n",
      "feature_fraction, val_score: 0.332675:  14%|#4        | 1/7 [00:04<00:28,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.332675\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.332675\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002710 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.348767\n",
      "[400]\tvalid_0's rmse: 0.341598\n",
      "[600]\tvalid_0's rmse: 0.337831\n",
      "[800]\tvalid_0's rmse: 0.335537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.332675:  29%|##8       | 2/7 [00:09<00:22,  4.46s/it]\u001b[32m[I 2021-10-21 09:26:47,789]\u001b[0m Trial 1 finished with value: 0.33391594437510125 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.33267493933975395.\u001b[0m\n",
      "feature_fraction, val_score: 0.332675:  29%|##8       | 2/7 [00:09<00:22,  4.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.333916\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.333916\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.349467\n",
      "[400]\tvalid_0's rmse: 0.342164\n",
      "[600]\tvalid_0's rmse: 0.338344\n",
      "[800]\tvalid_0's rmse: 0.335843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.332675:  43%|####2     | 3/7 [00:11<00:14,  3.72s/it]\u001b[32m[I 2021-10-21 09:26:50,632]\u001b[0m Trial 2 finished with value: 0.3342796328193156 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.33267493933975395.\u001b[0m\n",
      "feature_fraction, val_score: 0.332675:  43%|####2     | 3/7 [00:11<00:14,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.33428\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.33428\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[200]\tvalid_0's rmse: 0.353692\n",
      "[400]\tvalid_0's rmse: 0.346355\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[600]\tvalid_0's rmse: 0.341957\n",
      "[800]\tvalid_0's rmse: 0.338987\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.332675:  57%|#####7    | 4/7 [00:14<00:10,  3.40s/it]\u001b[32m[I 2021-10-21 09:26:53,549]\u001b[0m Trial 3 finished with value: 0.3366373285808113 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.33267493933975395.\u001b[0m\n",
      "feature_fraction, val_score: 0.332675:  57%|#####7    | 4/7 [00:14<00:10,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.336637\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.336637\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001754 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.347503\n",
      "[400]\tvalid_0's rmse: 0.340589\n",
      "[600]\tvalid_0's rmse: 0.336617\n",
      "[800]\tvalid_0's rmse: 0.334053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.332504:  71%|#######1  | 5/7 [00:19<00:07,  3.74s/it]\u001b[32m[I 2021-10-21 09:26:57,879]\u001b[0m Trial 4 finished with value: 0.3325043664701975 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.3325043664701975.\u001b[0m\n",
      "feature_fraction, val_score: 0.332504:  71%|#######1  | 5/7 [00:19<00:07,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.332504\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.332504\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.351434\n",
      "[400]\tvalid_0's rmse: 0.343911\n",
      "[600]\tvalid_0's rmse: 0.339826\n",
      "[800]\tvalid_0's rmse: 0.336963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.332504:  86%|########5 | 6/7 [00:23<00:03,  3.88s/it]\u001b[32m[I 2021-10-21 09:27:02,025]\u001b[0m Trial 5 finished with value: 0.33520833796163185 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.3325043664701975.\u001b[0m\n",
      "feature_fraction, val_score: 0.332504:  86%|########5 | 6/7 [00:23<00:03,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.335208\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.335208\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.347136\n",
      "[400]\tvalid_0's rmse: 0.340022\n",
      "[600]\tvalid_0's rmse: 0.336704\n",
      "[800]\tvalid_0's rmse: 0.334214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.332504: 100%|##########| 7/7 [00:26<00:00,  3.83s/it]\u001b[32m[I 2021-10-21 09:27:05,763]\u001b[0m Trial 6 finished with value: 0.3326032226369809 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.3325043664701975.\u001b[0m\n",
      "feature_fraction, val_score: 0.332504: 100%|##########| 7/7 [00:26<00:00,  3.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.332603\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.332603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.332504:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003949 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331853\n",
      "[400]\tvalid_0's rmse: 0.328782\n",
      "[600]\tvalid_0's rmse: 0.328104\n",
      "Early stopping, best iteration is:\n",
      "[652]\tvalid_0's rmse: 0.328016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328016:   5%|5         | 1/20 [00:04<01:27,  4.59s/it]\u001b[32m[I 2021-10-21 09:27:10,355]\u001b[0m Trial 7 finished with value: 0.32801606153166585 and parameters: {'num_leaves': 173}. Best is trial 7 with value: 0.32801606153166585.\u001b[0m\n",
      "num_leaves, val_score: 0.328016:   5%|5         | 1/20 [00:04<01:27,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.348444\n",
      "[400]\tvalid_0's rmse: 0.340801\n",
      "[600]\tvalid_0's rmse: 0.3373\n",
      "[800]\tvalid_0's rmse: 0.334745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.328016:  10%|#         | 2/20 [00:09<01:26,  4.79s/it]\u001b[32m[I 2021-10-21 09:27:15,287]\u001b[0m Trial 8 finished with value: 0.33308219276692713 and parameters: {'num_leaves': 29}. Best is trial 7 with value: 0.32801606153166585.\u001b[0m\n",
      "num_leaves, val_score: 0.328016:  10%|#         | 2/20 [00:09<01:26,  4.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.333086\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's rmse: 0.333082\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009763 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.333185\n",
      "[400]\tvalid_0's rmse: 0.330131\n",
      "[600]\tvalid_0's rmse: 0.328646\n",
      "[800]\tvalid_0's rmse: 0.328014\n",
      "[1000]\tvalid_0's rmse: 0.327742\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.327742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327742:  15%|#5        | 3/20 [00:16<01:36,  5.71s/it]\u001b[32m[I 2021-10-21 09:27:22,080]\u001b[0m Trial 9 finished with value: 0.32774241365193735 and parameters: {'num_leaves': 127}. Best is trial 9 with value: 0.32774241365193735.\u001b[0m\n",
      "num_leaves, val_score: 0.327742:  15%|#5        | 3/20 [00:16<01:36,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003085 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.333523\n",
      "[400]\tvalid_0's rmse: 0.329757\n",
      "[600]\tvalid_0's rmse: 0.328613\n",
      "[800]\tvalid_0's rmse: 0.328108\n",
      "[1000]\tvalid_0's rmse: 0.327861\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[995]\tvalid_0's rmse: 0.327848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327742:  20%|##        | 4/20 [00:21<01:27,  5.48s/it]\u001b[32m[I 2021-10-21 09:27:27,210]\u001b[0m Trial 10 finished with value: 0.3278475623583962 and parameters: {'num_leaves': 120}. Best is trial 9 with value: 0.32774241365193735.\u001b[0m\n",
      "num_leaves, val_score: 0.327742:  20%|##        | 4/20 [00:21<01:27,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002584 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.337156\n",
      "[400]\tvalid_0's rmse: 0.332615\n",
      "[600]\tvalid_0's rmse: 0.330479\n",
      "[800]\tvalid_0's rmse: 0.329478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327742:  25%|##5       | 5/20 [00:27<01:23,  5.57s/it]\u001b[32m[I 2021-10-21 09:27:32,936]\u001b[0m Trial 11 finished with value: 0.3289250146409766 and parameters: {'num_leaves': 77}. Best is trial 9 with value: 0.32774241365193735.\u001b[0m\n",
      "num_leaves, val_score: 0.327742:  25%|##5       | 5/20 [00:27<01:23,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.328925\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.328925\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003684 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331227\n",
      "[400]\tvalid_0's rmse: 0.328597\n",
      "[600]\tvalid_0's rmse: 0.327786\n",
      "[800]\tvalid_0's rmse: 0.327732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 0.327707:  25%|##5       | 5/20 [00:32<01:23,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[772]\tvalid_0's rmse: 0.327707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327707:  30%|###       | 6/20 [00:32<01:18,  5.59s/it]\u001b[32m[I 2021-10-21 09:27:38,563]\u001b[0m Trial 12 finished with value: 0.32770670128959634 and parameters: {'num_leaves': 176}. Best is trial 12 with value: 0.32770670128959634.\u001b[0m\n",
      "num_leaves, val_score: 0.327707:  30%|###       | 6/20 [00:32<01:18,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.333019\n",
      "[400]\tvalid_0's rmse: 0.32994\n",
      "[600]\tvalid_0's rmse: 0.32883\n",
      "[800]\tvalid_0's rmse: 0.328287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 0.327707:  30%|###       | 6/20 [00:37<01:18,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[856]\tvalid_0's rmse: 0.328226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327707:  35%|###5      | 7/20 [00:37<01:10,  5.39s/it]\u001b[32m[I 2021-10-21 09:27:43,534]\u001b[0m Trial 13 finished with value: 0.32822624780805537 and parameters: {'num_leaves': 125}. Best is trial 12 with value: 0.32770670128959634.\u001b[0m\n",
      "num_leaves, val_score: 0.327707:  35%|###5      | 7/20 [00:37<01:10,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003285 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332004\n",
      "[400]\tvalid_0's rmse: 0.329102\n",
      "[600]\tvalid_0's rmse: 0.327967\n",
      "[800]\tvalid_0's rmse: 0.327693\n",
      "Early stopping, best iteration is:\n",
      "[815]\tvalid_0's rmse: 0.327654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327654:  40%|####      | 8/20 [00:44<01:10,  5.86s/it]\u001b[32m[I 2021-10-21 09:27:50,412]\u001b[0m Trial 14 finished with value: 0.3276540537886479 and parameters: {'num_leaves': 157}. Best is trial 14 with value: 0.3276540537886479.\u001b[0m\n",
      "num_leaves, val_score: 0.327654:  40%|####      | 8/20 [00:44<01:10,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.335252\n",
      "[400]\tvalid_0's rmse: 0.330803\n",
      "[600]\tvalid_0's rmse: 0.328963\n",
      "[800]\tvalid_0's rmse: 0.328045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327654:  45%|####5     | 9/20 [00:49<01:00,  5.54s/it]\u001b[32m[I 2021-10-21 09:27:55,254]\u001b[0m Trial 15 finished with value: 0.32778531056426063 and parameters: {'num_leaves': 100}. Best is trial 14 with value: 0.3276540537886479.\u001b[0m\n",
      "num_leaves, val_score: 0.327654:  45%|####5     | 9/20 [00:49<01:00,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.327785\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.327785\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.329939\n",
      "[400]\tvalid_0's rmse: 0.328119\n",
      "[600]\tvalid_0's rmse: 0.327746\n",
      "Early stopping, best iteration is:\n",
      "[607]\tvalid_0's rmse: 0.32774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327654:  50%|#####     | 10/20 [00:54<00:53,  5.30s/it]\u001b[32m[I 2021-10-21 09:28:00,017]\u001b[0m Trial 16 finished with value: 0.3277404041908048 and parameters: {'num_leaves': 209}. Best is trial 14 with value: 0.3276540537886479.\u001b[0m\n",
      "num_leaves, val_score: 0.327654:  50%|#####     | 10/20 [00:54<00:53,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.329378\n",
      "[400]\tvalid_0's rmse: 0.328034\n",
      "[600]\tvalid_0's rmse: 0.327939\n",
      "Early stopping, best iteration is:\n",
      "[543]\tvalid_0's rmse: 0.32783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327654:  55%|#####5    | 11/20 [01:00<00:50,  5.60s/it]\u001b[32m[I 2021-10-21 09:28:06,287]\u001b[0m Trial 17 finished with value: 0.3278295896268349 and parameters: {'num_leaves': 247}. Best is trial 14 with value: 0.3276540537886479.\u001b[0m\n",
      "num_leaves, val_score: 0.327654:  55%|#####5    | 11/20 [01:00<00:50,  5.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.330386\n",
      "[400]\tvalid_0's rmse: 0.328249\n",
      "[600]\tvalid_0's rmse: 0.327822\n",
      "Early stopping, best iteration is:\n",
      "[635]\tvalid_0's rmse: 0.327716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327654:  60%|######    | 12/20 [01:05<00:44,  5.56s/it]\u001b[32m[I 2021-10-21 09:28:11,760]\u001b[0m Trial 18 finished with value: 0.3277163946671655 and parameters: {'num_leaves': 182}. Best is trial 14 with value: 0.3276540537886479.\u001b[0m\n",
      "num_leaves, val_score: 0.327654:  60%|######    | 12/20 [01:05<00:44,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002931 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.330854\n",
      "[400]\tvalid_0's rmse: 0.328475\n",
      "[600]\tvalid_0's rmse: 0.327706\n",
      "Early stopping, best iteration is:\n",
      "[683]\tvalid_0's rmse: 0.327632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327632:  65%|######5   | 13/20 [01:14<00:44,  6.41s/it]\u001b[32m[I 2021-10-21 09:28:20,119]\u001b[0m Trial 19 finished with value: 0.3276324870475347 and parameters: {'num_leaves': 169}. Best is trial 19 with value: 0.3276324870475347.\u001b[0m\n",
      "num_leaves, val_score: 0.327632:  65%|######5   | 13/20 [01:14<00:44,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.329906\n",
      "[400]\tvalid_0's rmse: 0.32816\n",
      "[600]\tvalid_0's rmse: 0.327942\n",
      "Early stopping, best iteration is:\n",
      "[589]\tvalid_0's rmse: 0.327897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327632:  70%|#######   | 14/20 [01:21<00:39,  6.59s/it]\u001b[32m[I 2021-10-21 09:28:27,144]\u001b[0m Trial 20 finished with value: 0.3278971085071634 and parameters: {'num_leaves': 224}. Best is trial 19 with value: 0.3276324870475347.\u001b[0m\n",
      "num_leaves, val_score: 0.327632:  70%|#######   | 14/20 [01:21<00:39,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331879\n",
      "[400]\tvalid_0's rmse: 0.328514\n",
      "[600]\tvalid_0's rmse: 0.327618\n",
      "[800]\tvalid_0's rmse: 0.327477\n",
      "Early stopping, best iteration is:\n",
      "[751]\tvalid_0's rmse: 0.327436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327436:  75%|#######5  | 15/20 [01:26<00:31,  6.21s/it]\u001b[32m[I 2021-10-21 09:28:32,469]\u001b[0m Trial 21 finished with value: 0.3274358683209632 and parameters: {'num_leaves': 160}. Best is trial 21 with value: 0.3274358683209632.\u001b[0m\n",
      "num_leaves, val_score: 0.327436:  75%|#######5  | 15/20 [01:26<00:31,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.338734\n",
      "[400]\tvalid_0's rmse: 0.333218\n",
      "[600]\tvalid_0's rmse: 0.330854\n",
      "[800]\tvalid_0's rmse: 0.329625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327436:  80%|########  | 16/20 [01:32<00:24,  6.06s/it]\u001b[32m[I 2021-10-21 09:28:38,194]\u001b[0m Trial 22 finished with value: 0.3290009316215895 and parameters: {'num_leaves': 68}. Best is trial 21 with value: 0.3274358683209632.\u001b[0m\n",
      "num_leaves, val_score: 0.327436:  80%|########  | 16/20 [01:32<00:24,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.329042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[985]\tvalid_0's rmse: 0.329001\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003537 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.329836\n",
      "[400]\tvalid_0's rmse: 0.328096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327436:  85%|########5 | 17/20 [01:36<00:16,  5.54s/it]\u001b[32m[I 2021-10-21 09:28:42,508]\u001b[0m Trial 23 finished with value: 0.327840388477554 and parameters: {'num_leaves': 207}. Best is trial 21 with value: 0.3274358683209632.\u001b[0m\n",
      "num_leaves, val_score: 0.327436:  85%|########5 | 17/20 [01:36<00:16,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\tvalid_0's rmse: 0.327937\n",
      "Early stopping, best iteration is:\n",
      "[500]\tvalid_0's rmse: 0.32784\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332393\n",
      "[400]\tvalid_0's rmse: 0.329233\n",
      "[600]\tvalid_0's rmse: 0.328333\n",
      "[800]\tvalid_0's rmse: 0.328165\n",
      "Early stopping, best iteration is:\n",
      "[781]\tvalid_0's rmse: 0.32813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327436:  90%|######### | 18/20 [01:41<00:10,  5.20s/it]\u001b[32m[I 2021-10-21 09:28:46,925]\u001b[0m Trial 24 finished with value: 0.3281303021299798 and parameters: {'num_leaves': 152}. Best is trial 21 with value: 0.3274358683209632.\u001b[0m\n",
      "num_leaves, val_score: 0.327436:  90%|######### | 18/20 [01:41<00:10,  5.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002940 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.473686\n",
      "[400]\tvalid_0's rmse: 0.441\n",
      "[600]\tvalid_0's rmse: 0.422532\n",
      "[800]\tvalid_0's rmse: 0.410142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327436:  95%|#########5| 19/20 [01:43<00:04,  4.45s/it]\u001b[32m[I 2021-10-21 09:28:49,618]\u001b[0m Trial 25 finished with value: 0.4013346866924358 and parameters: {'num_leaves': 2}. Best is trial 21 with value: 0.3274358683209632.\u001b[0m\n",
      "num_leaves, val_score: 0.327436:  95%|#########5| 19/20 [01:43<00:04,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.401335\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.401335\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332393\n",
      "[400]\tvalid_0's rmse: 0.329233\n",
      "[600]\tvalid_0's rmse: 0.328333\n",
      "[800]\tvalid_0's rmse: 0.328165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "num_leaves, val_score: 0.327436:  95%|#########5| 19/20 [01:49<00:04,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[781]\tvalid_0's rmse: 0.32813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.327436: 100%|##########| 20/20 [01:49<00:00,  4.95s/it]\u001b[32m[I 2021-10-21 09:28:55,723]\u001b[0m Trial 26 finished with value: 0.3281303021299798 and parameters: {'num_leaves': 152}. Best is trial 21 with value: 0.3274358683209632.\u001b[0m\n",
      "num_leaves, val_score: 0.327436: 100%|##########| 20/20 [01:49<00:00,  5.50s/it]\n",
      "bagging, val_score: 0.327436:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332842\n",
      "[400]\tvalid_0's rmse: 0.330461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  10%|#         | 1/10 [00:03<00:32,  3.65s/it]\u001b[32m[I 2021-10-21 09:28:59,378]\u001b[0m Trial 27 finished with value: 0.3303904197362435 and parameters: {'bagging_fraction': 0.5134051431119648, 'bagging_freq': 2}. Best is trial 27 with value: 0.3303904197362435.\u001b[0m\n",
      "bagging, val_score: 0.327436:  10%|#         | 1/10 [00:03<00:32,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[409]\tvalid_0's rmse: 0.33039\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331802\n",
      "[400]\tvalid_0's rmse: 0.328795\n",
      "[600]\tvalid_0's rmse: 0.328052\n",
      "[800]\tvalid_0's rmse: 0.328005\n",
      "Early stopping, best iteration is:\n",
      "[739]\tvalid_0's rmse: 0.327924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  20%|##        | 2/10 [00:10<00:43,  5.48s/it]\u001b[32m[I 2021-10-21 09:29:06,148]\u001b[0m Trial 28 finished with value: 0.32792355774091686 and parameters: {'bagging_fraction': 0.8987769464709569, 'bagging_freq': 4}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  20%|##        | 2/10 [00:10<00:43,  5.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009555 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.333007\n",
      "[400]\tvalid_0's rmse: 0.330794\n",
      "[600]\tvalid_0's rmse: 0.330472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  30%|###       | 3/10 [00:17<00:42,  6.08s/it]\u001b[32m[I 2021-10-21 09:29:12,945]\u001b[0m Trial 29 finished with value: 0.33040885006649 and parameters: {'bagging_fraction': 0.5852800139871447, 'bagging_freq': 5}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  30%|###       | 3/10 [00:17<00:42,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[615]\tvalid_0's rmse: 0.330409\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001974 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332076\n",
      "[400]\tvalid_0's rmse: 0.329862\n",
      "[600]\tvalid_0's rmse: 0.32933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  40%|####      | 4/10 [00:21<00:32,  5.39s/it]\u001b[32m[I 2021-10-21 09:29:17,283]\u001b[0m Trial 30 finished with value: 0.3292353973914534 and parameters: {'bagging_fraction': 0.5777557806027537, 'bagging_freq': 1}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  40%|####      | 4/10 [00:21<00:32,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[581]\tvalid_0's rmse: 0.329235\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332948\n",
      "[400]\tvalid_0's rmse: 0.33081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  50%|#####     | 5/10 [00:27<00:27,  5.59s/it]\u001b[32m[I 2021-10-21 09:29:23,227]\u001b[0m Trial 31 finished with value: 0.33055970796383155 and parameters: {'bagging_fraction': 0.5171988905399036, 'bagging_freq': 2}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  50%|#####     | 5/10 [00:27<00:27,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[461]\tvalid_0's rmse: 0.33056\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.333076\n",
      "[400]\tvalid_0's rmse: 0.330718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  60%|######    | 6/10 [00:32<00:21,  5.42s/it]\u001b[32m[I 2021-10-21 09:29:28,301]\u001b[0m Trial 32 finished with value: 0.3306032180174649 and parameters: {'bagging_fraction': 0.5312076444037281, 'bagging_freq': 5}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  60%|######    | 6/10 [00:32<00:21,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[435]\tvalid_0's rmse: 0.330603\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332249\n",
      "[400]\tvalid_0's rmse: 0.329237\n",
      "[600]\tvalid_0's rmse: 0.32846\n",
      "[800]\tvalid_0's rmse: 0.32808\n",
      "Early stopping, best iteration is:\n",
      "[847]\tvalid_0's rmse: 0.328002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  70%|#######   | 7/10 [00:38<00:16,  5.55s/it]\u001b[32m[I 2021-10-21 09:29:34,125]\u001b[0m Trial 33 finished with value: 0.3280016795557504 and parameters: {'bagging_fraction': 0.9406650054878108, 'bagging_freq': 6}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  70%|#######   | 7/10 [00:38<00:16,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332799\n",
      "[400]\tvalid_0's rmse: 0.330049\n",
      "[600]\tvalid_0's rmse: 0.329606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "bagging, val_score: 0.327436:  70%|#######   | 7/10 [00:45<00:16,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[680]\tvalid_0's rmse: 0.329542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  80%|########  | 8/10 [00:45<00:12,  6.16s/it]\u001b[32m[I 2021-10-21 09:29:41,576]\u001b[0m Trial 34 finished with value: 0.329542236148635 and parameters: {'bagging_fraction': 0.6745847027945785, 'bagging_freq': 7}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  80%|########  | 8/10 [00:45<00:12,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002806 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332858\n",
      "[400]\tvalid_0's rmse: 0.330261\n",
      "[600]\tvalid_0's rmse: 0.32976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436:  90%|######### | 9/10 [00:50<00:05,  5.78s/it]\u001b[32m[I 2021-10-21 09:29:46,519]\u001b[0m Trial 35 finished with value: 0.3296879704621616 and parameters: {'bagging_fraction': 0.6723555028550616, 'bagging_freq': 6}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436:  90%|######### | 9/10 [00:50<00:05,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[579]\tvalid_0's rmse: 0.329688\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331888\n",
      "[400]\tvalid_0's rmse: 0.329411\n",
      "[600]\tvalid_0's rmse: 0.328927\n",
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's rmse: 0.328782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.327436: 100%|##########| 10/10 [00:56<00:00,  5.76s/it]\u001b[32m[I 2021-10-21 09:29:52,257]\u001b[0m Trial 36 finished with value: 0.32878179750264785 and parameters: {'bagging_fraction': 0.7000204545212725, 'bagging_freq': 5}. Best is trial 28 with value: 0.32792355774091686.\u001b[0m\n",
      "bagging, val_score: 0.327436: 100%|##########| 10/10 [00:56<00:00,  5.65s/it]\n",
      "feature_fraction_stage2, val_score: 0.327436:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331805\n",
      "[400]\tvalid_0's rmse: 0.328918\n",
      "[600]\tvalid_0's rmse: 0.327914\n",
      "[800]\tvalid_0's rmse: 0.327437\n",
      "Early stopping, best iteration is:\n",
      "[854]\tvalid_0's rmse: 0.327415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.327415:  33%|###3      | 1/3 [00:06<00:13,  6.86s/it]\u001b[32m[I 2021-10-21 09:29:59,126]\u001b[0m Trial 37 finished with value: 0.3274153708048721 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.3274153708048721.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327415:  33%|###3      | 1/3 [00:06<00:13,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002798 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331879\n",
      "[400]\tvalid_0's rmse: 0.328514\n",
      "[600]\tvalid_0's rmse: 0.327618\n",
      "[800]\tvalid_0's rmse: 0.327477\n",
      "Early stopping, best iteration is:\n",
      "[751]\tvalid_0's rmse: 0.327436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.327415:  67%|######6   | 2/3 [00:11<00:05,  5.38s/it]\u001b[32m[I 2021-10-21 09:30:03,465]\u001b[0m Trial 38 finished with value: 0.3274358683209632 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.3274153708048721.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327415:  67%|######6   | 2/3 [00:11<00:05,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003167 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331805\n",
      "[400]\tvalid_0's rmse: 0.328918\n",
      "[600]\tvalid_0's rmse: 0.327914\n",
      "[800]\tvalid_0's rmse: 0.327437\n",
      "Early stopping, best iteration is:\n",
      "[854]\tvalid_0's rmse: 0.327415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.327415: 100%|##########| 3/3 [00:16<00:00,  5.47s/it]\u001b[32m[I 2021-10-21 09:30:09,042]\u001b[0m Trial 39 finished with value: 0.3274153708048721 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 37 with value: 0.3274153708048721.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.327415: 100%|##########| 3/3 [00:16<00:00,  5.59s/it]\n",
      "regularization_factors, val_score: 0.327415:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002815 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332017\n",
      "[400]\tvalid_0's rmse: 0.32854\n",
      "[600]\tvalid_0's rmse: 0.32735\n",
      "[800]\tvalid_0's rmse: 0.327103\n",
      "Early stopping, best iteration is:\n",
      "[738]\tvalid_0's rmse: 0.327015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.327015:   5%|5         | 1/20 [00:06<02:04,  6.55s/it]\u001b[32m[I 2021-10-21 09:30:15,602]\u001b[0m Trial 40 finished with value: 0.327014528139228 and parameters: {'lambda_l1': 0.23148472241851556, 'lambda_l2': 0.0019754515130430217}. Best is trial 40 with value: 0.327014528139228.\u001b[0m\n",
      "regularization_factors, val_score: 0.327015:   5%|5         | 1/20 [00:06<02:04,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.33172\n",
      "[400]\tvalid_0's rmse: 0.328504\n",
      "[600]\tvalid_0's rmse: 0.327717\n",
      "[800]\tvalid_0's rmse: 0.327329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 0.327015:   5%|5         | 1/20 [00:11<02:04,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[895]\tvalid_0's rmse: 0.327268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.327015:  10%|#         | 2/20 [00:11<01:42,  5.67s/it]\u001b[32m[I 2021-10-21 09:30:20,651]\u001b[0m Trial 41 finished with value: 0.3272676449496459 and parameters: {'lambda_l1': 4.681522063822202e-06, 'lambda_l2': 0.00010222414617618337}. Best is trial 40 with value: 0.327014528139228.\u001b[0m\n",
      "regularization_factors, val_score: 0.327015:  10%|#         | 2/20 [00:11<01:42,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002029 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332122\n",
      "[400]\tvalid_0's rmse: 0.328954\n",
      "[600]\tvalid_0's rmse: 0.327898\n",
      "[800]\tvalid_0's rmse: 0.327446\n",
      "Early stopping, best iteration is:\n",
      "[802]\tvalid_0's rmse: 0.327422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.327015:  15%|#5        | 3/20 [00:17<01:41,  5.99s/it]\u001b[32m[I 2021-10-21 09:30:27,025]\u001b[0m Trial 42 finished with value: 0.32742241285825435 and parameters: {'lambda_l1': 0.0005703262266941216, 'lambda_l2': 0.029415785752409895}. Best is trial 40 with value: 0.327014528139228.\u001b[0m\n",
      "regularization_factors, val_score: 0.327015:  15%|#5        | 3/20 [00:17<01:41,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332223\n",
      "[400]\tvalid_0's rmse: 0.329244\n",
      "[600]\tvalid_0's rmse: 0.328066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.327015:  20%|##        | 4/20 [00:23<01:33,  5.82s/it]\u001b[32m[I 2021-10-21 09:30:32,576]\u001b[0m Trial 43 finished with value: 0.3278456012385566 and parameters: {'lambda_l1': 0.0005873628057456142, 'lambda_l2': 8.56446348178353e-08}. Best is trial 40 with value: 0.327014528139228.\u001b[0m\n",
      "regularization_factors, val_score: 0.327015:  20%|##        | 4/20 [00:23<01:33,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's rmse: 0.327846\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332188\n",
      "[400]\tvalid_0's rmse: 0.328818\n",
      "[600]\tvalid_0's rmse: 0.327684\n",
      "[800]\tvalid_0's rmse: 0.327504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 0.327015:  20%|##        | 4/20 [00:28<01:33,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[898]\tvalid_0's rmse: 0.327384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.327015:  25%|##5       | 5/20 [00:28<01:22,  5.52s/it]\u001b[32m[I 2021-10-21 09:30:37,560]\u001b[0m Trial 44 finished with value: 0.32738444439659625 and parameters: {'lambda_l1': 2.2137374594716345e-07, 'lambda_l2': 4.286996513475764e-05}. Best is trial 40 with value: 0.327014528139228.\u001b[0m\n",
      "regularization_factors, val_score: 0.327015:  25%|##5       | 5/20 [00:28<01:22,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331759\n",
      "[400]\tvalid_0's rmse: 0.328726\n",
      "[600]\tvalid_0's rmse: 0.327542\n",
      "[800]\tvalid_0's rmse: 0.3272\n",
      "[1000]\tvalid_0's rmse: 0.327102\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[988]\tvalid_0's rmse: 0.327065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.327015:  30%|###       | 6/20 [00:35<01:26,  6.16s/it]\u001b[32m[I 2021-10-21 09:30:44,974]\u001b[0m Trial 45 finished with value: 0.3270650092346227 and parameters: {'lambda_l1': 0.11446415237297204, 'lambda_l2': 6.495420643012327}. Best is trial 40 with value: 0.327014528139228.\u001b[0m\n",
      "regularization_factors, val_score: 0.327015:  30%|###       | 6/20 [00:35<01:26,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331529\n",
      "[400]\tvalid_0's rmse: 0.328533\n",
      "[600]\tvalid_0's rmse: 0.327462\n",
      "[800]\tvalid_0's rmse: 0.327052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 0.326852:  30%|###       | 6/20 [00:41<01:26,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[891]\tvalid_0's rmse: 0.326852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326852:  35%|###5      | 7/20 [00:41<01:19,  6.13s/it]\u001b[32m[I 2021-10-21 09:30:51,029]\u001b[0m Trial 46 finished with value: 0.32685187858129733 and parameters: {'lambda_l1': 0.6408904109350804, 'lambda_l2': 0.054821974221052706}. Best is trial 46 with value: 0.32685187858129733.\u001b[0m\n",
      "regularization_factors, val_score: 0.326852:  35%|###5      | 7/20 [00:41<01:19,  6.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332012\n",
      "[400]\tvalid_0's rmse: 0.32867\n",
      "[600]\tvalid_0's rmse: 0.327604\n",
      "[800]\tvalid_0's rmse: 0.327119\n",
      "[1000]\tvalid_0's rmse: 0.327125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[903]\tvalid_0's rmse: 0.327052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326852:  40%|####      | 8/20 [00:47<01:12,  6.06s/it]\u001b[32m[I 2021-10-21 09:30:56,937]\u001b[0m Trial 47 finished with value: 0.3270522524015006 and parameters: {'lambda_l1': 0.024585490239221422, 'lambda_l2': 1.671447716068279e-08}. Best is trial 46 with value: 0.32685187858129733.\u001b[0m\n",
      "regularization_factors, val_score: 0.326852:  40%|####      | 8/20 [00:47<01:12,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331808\n",
      "[400]\tvalid_0's rmse: 0.328915\n",
      "[600]\tvalid_0's rmse: 0.327991\n",
      "[800]\tvalid_0's rmse: 0.32764\n",
      "Early stopping, best iteration is:\n",
      "[833]\tvalid_0's rmse: 0.327609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326852:  45%|####5     | 9/20 [00:54<01:09,  6.32s/it]\u001b[32m[I 2021-10-21 09:31:03,825]\u001b[0m Trial 48 finished with value: 0.3276092441560713 and parameters: {'lambda_l1': 1.5223228287900507e-08, 'lambda_l2': 0.02760874157422704}. Best is trial 46 with value: 0.32685187858129733.\u001b[0m\n",
      "regularization_factors, val_score: 0.326852:  45%|####5     | 9/20 [00:54<01:09,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003218 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332094\n",
      "[400]\tvalid_0's rmse: 0.328553\n",
      "[600]\tvalid_0's rmse: 0.327663\n",
      "[800]\tvalid_0's rmse: 0.327323\n",
      "[1000]\tvalid_0's rmse: 0.327306\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[920]\tvalid_0's rmse: 0.327201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326852:  50%|#####     | 10/20 [01:00<01:00,  6.07s/it]\u001b[32m[I 2021-10-21 09:31:09,348]\u001b[0m Trial 49 finished with value: 0.327200889815829 and parameters: {'lambda_l1': 0.004877532393863776, 'lambda_l2': 9.865717932780969e-08}. Best is trial 46 with value: 0.32685187858129733.\u001b[0m\n",
      "regularization_factors, val_score: 0.326852:  50%|#####     | 10/20 [01:00<01:00,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.333625\n",
      "[400]\tvalid_0's rmse: 0.330269\n",
      "[600]\tvalid_0's rmse: 0.329115\n",
      "[800]\tvalid_0's rmse: 0.328626\n",
      "[1000]\tvalid_0's rmse: 0.32832\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[975]\tvalid_0's rmse: 0.328312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326852:  55%|#####5    | 11/20 [01:10<01:05,  7.30s/it]\u001b[32m[I 2021-10-21 09:31:19,445]\u001b[0m Trial 50 finished with value: 0.32831190738939386 and parameters: {'lambda_l1': 8.073349529016472, 'lambda_l2': 9.52383382030833}. Best is trial 46 with value: 0.32685187858129733.\u001b[0m\n",
      "regularization_factors, val_score: 0.326852:  55%|#####5    | 11/20 [01:10<01:05,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002745 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332421\n",
      "[400]\tvalid_0's rmse: 0.329549\n",
      "[600]\tvalid_0's rmse: 0.328266\n",
      "[800]\tvalid_0's rmse: 0.327763\n",
      "[1000]\tvalid_0's rmse: 0.327577\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[999]\tvalid_0's rmse: 0.327571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326852:  60%|######    | 12/20 [01:17<00:58,  7.28s/it]\u001b[32m[I 2021-10-21 09:31:26,665]\u001b[0m Trial 51 finished with value: 0.3275714106818578 and parameters: {'lambda_l1': 6.725190882806047, 'lambda_l2': 0.008784008973550321}. Best is trial 46 with value: 0.32685187858129733.\u001b[0m\n",
      "regularization_factors, val_score: 0.326852:  60%|######    | 12/20 [01:17<00:58,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331606\n",
      "[400]\tvalid_0's rmse: 0.328491\n",
      "[600]\tvalid_0's rmse: 0.327429\n",
      "[800]\tvalid_0's rmse: 0.327184\n",
      "Early stopping, best iteration is:\n",
      "[765]\tvalid_0's rmse: 0.327136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326852:  65%|######5   | 13/20 [01:24<00:49,  7.10s/it]\u001b[32m[I 2021-10-21 09:31:33,340]\u001b[0m Trial 52 finished with value: 0.32713601102102446 and parameters: {'lambda_l1': 0.3300840267273945, 'lambda_l2': 0.002252522984984122}. Best is trial 46 with value: 0.32685187858129733.\u001b[0m\n",
      "regularization_factors, val_score: 0.326852:  65%|######5   | 13/20 [01:24<00:49,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002731 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331532\n",
      "[400]\tvalid_0's rmse: 0.328309\n",
      "[600]\tvalid_0's rmse: 0.32734\n",
      "[800]\tvalid_0's rmse: 0.326988\n",
      "[1000]\tvalid_0's rmse: 0.326836\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[954]\tvalid_0's rmse: 0.326787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326787:  70%|#######   | 14/20 [01:30<00:40,  6.72s/it]\u001b[32m[I 2021-10-21 09:31:39,190]\u001b[0m Trial 53 finished with value: 0.326786918866301 and parameters: {'lambda_l1': 0.2901156134573577, 'lambda_l2': 0.34789645006171777}. Best is trial 53 with value: 0.326786918866301.\u001b[0m\n",
      "regularization_factors, val_score: 0.326787:  70%|#######   | 14/20 [01:30<00:40,  6.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.33207\n",
      "[400]\tvalid_0's rmse: 0.328905\n",
      "[600]\tvalid_0's rmse: 0.327922\n",
      "[800]\tvalid_0's rmse: 0.327581\n",
      "Early stopping, best iteration is:\n",
      "[715]\tvalid_0's rmse: 0.327533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326787:  75%|#######5  | 15/20 [01:34<00:30,  6.14s/it]\u001b[32m[I 2021-10-21 09:31:43,994]\u001b[0m Trial 54 finished with value: 0.32753298927125846 and parameters: {'lambda_l1': 2.0132017796835853e-05, 'lambda_l2': 0.3697221714967442}. Best is trial 53 with value: 0.326786918866301.\u001b[0m\n",
      "regularization_factors, val_score: 0.326787:  75%|#######5  | 15/20 [01:34<00:30,  6.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331527\n",
      "[400]\tvalid_0's rmse: 0.328247\n",
      "[600]\tvalid_0's rmse: 0.327201\n",
      "[800]\tvalid_0's rmse: 0.326746\n",
      "[1000]\tvalid_0's rmse: 0.326592\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[978]\tvalid_0's rmse: 0.326571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326571:  80%|########  | 16/20 [01:42<00:26,  6.69s/it]\u001b[32m[I 2021-10-21 09:31:51,967]\u001b[0m Trial 55 finished with value: 0.32657149920137696 and parameters: {'lambda_l1': 1.7000031637532123, 'lambda_l2': 0.3387511918792376}. Best is trial 55 with value: 0.32657149920137696.\u001b[0m\n",
      "regularization_factors, val_score: 0.326571:  80%|########  | 16/20 [01:42<00:26,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332224\n",
      "[400]\tvalid_0's rmse: 0.328712\n",
      "[600]\tvalid_0's rmse: 0.328032\n",
      "[800]\tvalid_0's rmse: 0.327676\n",
      "Early stopping, best iteration is:\n",
      "[754]\tvalid_0's rmse: 0.327609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326571:  85%|########5 | 17/20 [01:47<00:17,  5.98s/it]\u001b[32m[I 2021-10-21 09:31:56,286]\u001b[0m Trial 56 finished with value: 0.32760949379389825 and parameters: {'lambda_l1': 0.007126677907134323, 'lambda_l2': 0.5586317251210421}. Best is trial 55 with value: 0.32657149920137696.\u001b[0m\n",
      "regularization_factors, val_score: 0.326571:  85%|########5 | 17/20 [01:47<00:17,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331591\n",
      "[400]\tvalid_0's rmse: 0.328316\n",
      "[600]\tvalid_0's rmse: 0.32727\n",
      "[800]\tvalid_0's rmse: 0.326903\n",
      "[1000]\tvalid_0's rmse: 0.326756\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[992]\tvalid_0's rmse: 0.326746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326571:  90%|######### | 18/20 [01:54<00:12,  6.44s/it]\u001b[32m[I 2021-10-21 09:32:03,811]\u001b[0m Trial 57 finished with value: 0.3267462143519631 and parameters: {'lambda_l1': 1.8834461149180453, 'lambda_l2': 3.4984654922410857e-06}. Best is trial 55 with value: 0.32657149920137696.\u001b[0m\n",
      "regularization_factors, val_score: 0.326571:  90%|######### | 18/20 [01:54<00:12,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331519\n",
      "[400]\tvalid_0's rmse: 0.328263\n",
      "[600]\tvalid_0's rmse: 0.327144\n",
      "[800]\tvalid_0's rmse: 0.326641\n",
      "[1000]\tvalid_0's rmse: 0.326361\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's rmse: 0.32636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326360:  95%|#########5| 19/20 [02:02<00:06,  6.81s/it]\u001b[32m[I 2021-10-21 09:32:11,484]\u001b[0m Trial 58 finished with value: 0.32636037296891773 and parameters: {'lambda_l1': 2.5659364367781405, 'lambda_l2': 4.976354635576488e-06}. Best is trial 58 with value: 0.32636037296891773.\u001b[0m\n",
      "regularization_factors, val_score: 0.326360:  95%|#########5| 19/20 [02:02<00:06,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.33148\n",
      "[400]\tvalid_0's rmse: 0.32889\n",
      "[600]\tvalid_0's rmse: 0.32789\n",
      "[800]\tvalid_0's rmse: 0.327592\n",
      "Early stopping, best iteration is:\n",
      "[884]\tvalid_0's rmse: 0.32745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.326360: 100%|##########| 20/20 [02:08<00:00,  6.60s/it]\u001b[32m[I 2021-10-21 09:32:17,593]\u001b[0m Trial 59 finished with value: 0.32744989955029913 and parameters: {'lambda_l1': 0.020657648477261235, 'lambda_l2': 4.039943997762507e-06}. Best is trial 58 with value: 0.32636037296891773.\u001b[0m\n",
      "regularization_factors, val_score: 0.326360: 100%|##########| 20/20 [02:08<00:00,  6.43s/it]\n",
      "min_data_in_leaf, val_score: 0.326360:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.33189\n",
      "[400]\tvalid_0's rmse: 0.328809\n",
      "[600]\tvalid_0's rmse: 0.327848\n",
      "[800]\tvalid_0's rmse: 0.327278\n",
      "[1000]\tvalid_0's rmse: 0.327056\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1000]\tvalid_0's rmse: 0.327056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.326360:  20%|##        | 1/5 [00:07<00:31,  7.96s/it]\u001b[32m[I 2021-10-21 09:32:25,558]\u001b[0m Trial 60 finished with value: 0.3270555300680927 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.3270555300680927.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.326360:  20%|##        | 1/5 [00:07<00:31,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331206\n",
      "[400]\tvalid_0's rmse: 0.328486\n",
      "[600]\tvalid_0's rmse: 0.327328\n",
      "[800]\tvalid_0's rmse: 0.326828\n",
      "[1000]\tvalid_0's rmse: 0.326487\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[997]\tvalid_0's rmse: 0.326484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.326360:  40%|####      | 2/5 [00:14<00:21,  7.12s/it]\u001b[32m[I 2021-10-21 09:32:32,094]\u001b[0m Trial 61 finished with value: 0.3264838954196695 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.3264838954196695.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.326360:  40%|####      | 2/5 [00:14<00:21,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004039 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331152\n",
      "[400]\tvalid_0's rmse: 0.328172\n",
      "[600]\tvalid_0's rmse: 0.326966\n",
      "[800]\tvalid_0's rmse: 0.3265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "min_data_in_leaf, val_score: 0.326271:  40%|####      | 2/5 [00:22<00:21,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.326272\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[966]\tvalid_0's rmse: 0.326271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.326271:  60%|######    | 3/5 [00:22<00:15,  7.64s/it]\u001b[32m[I 2021-10-21 09:32:40,345]\u001b[0m Trial 62 finished with value: 0.3262707545951734 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.3262707545951734.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.326271:  60%|######    | 3/5 [00:22<00:15,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002017 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.331818\n",
      "[400]\tvalid_0's rmse: 0.3281\n",
      "[600]\tvalid_0's rmse: 0.326881\n",
      "[800]\tvalid_0's rmse: 0.326363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "min_data_in_leaf, val_score: 0.326186:  60%|######    | 3/5 [00:28<00:15,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000]\tvalid_0's rmse: 0.326187\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[998]\tvalid_0's rmse: 0.326186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.326186:  80%|########  | 4/5 [00:28<00:06,  6.82s/it]\u001b[32m[I 2021-10-21 09:32:45,902]\u001b[0m Trial 63 finished with value: 0.32618649765483754 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.32618649765483754.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.326186:  80%|########  | 4/5 [00:28<00:06,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 600\n",
      "[LightGBM] [Info] Number of data points in the train set: 396048, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 8.939118\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's rmse: 0.332537\n",
      "[400]\tvalid_0's rmse: 0.329333\n",
      "[600]\tvalid_0's rmse: 0.328088\n",
      "[800]\tvalid_0's rmse: 0.327799\n",
      "[1000]\tvalid_0's rmse: 0.327713\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[937]\tvalid_0's rmse: 0.327664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.326186: 100%|##########| 5/5 [00:37<00:00,  7.53s/it]\u001b[32m[I 2021-10-21 09:32:54,714]\u001b[0m Trial 64 finished with value: 0.32766392290813384 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.32618649765483754.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.326186: 100%|##########| 5/5 [00:37<00:00,  7.42s/it]\n"
     ]
    }
   ],
   "source": [
    "gbm_o = lgb_o.train(params,\n",
    "                    train_gbm,\n",
    "                    valid_sets=val_gbm,\n",
    "                    early_stopping_rounds=100,\n",
    "                    verbose_eval=200,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_trainval_pred = gbm_o.predict(X_train,num_iteration=gbm_o.best_iteration)\n",
    "y_test_pred = gbm_o.predict(X_test,num_iteration=gbm_o.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Params: \n",
      "    objective: regression\n",
      "    metric: rmse\n",
      "    random_seed: 0\n",
      "    feature_pre_filter: False\n",
      "    lambda_l1: 2.5659364367781405\n",
      "    lambda_l2: 4.976354635576488e-06\n",
      "    num_leaves: 160\n",
      "    feature_fraction: 0.92\n",
      "    bagging_fraction: 1.0\n",
      "    bagging_freq: 0\n",
      "    min_child_samples: 5\n",
      "    num_iterations: 1000\n",
      "    early_stopping_round: 100\n"
     ]
    }
   ],
   "source": [
    "# Optunaで得た最適パラメータの表示\n",
    "best_params = gbm_o.params\n",
    "print(\"  Params: \")\n",
    "for key, value in best_params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_train: 0.29921142612404134\n",
      "rmse_test: 0.36092159988199285\n",
      "------------------------------\n",
      "GBM_O Train Score: 0.8368523496337477\n",
      "GBM_O Train Score: 0.761067461354535\n"
     ]
    }
   ],
   "source": [
    "GBM_O_TRAIN = np.sqrt(mean_squared_error(y_train,y_trainval_pred))\n",
    "GBM_O_TEST = np.sqrt(mean_squared_error(y_test,y_test_pred))\n",
    "print('rmse_train:',GBM_O_TRAIN)\n",
    "print('rmse_test:',GBM_O_TEST)\n",
    "print('-'*30)\n",
    "print('GBM_O Train Score:',r2_score(y_train,y_trainval_pred))\n",
    "print('GBM_O Train Score:',r2_score(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBMにより精度は少し向上させることができました。<br>\n",
    "ここでの気づきとしては、パラメータ調整で若干の向上はできても劇的な改善は難しいということです。<br>\n",
    "モデルはあくまでも表現であり、データそのものが精度向上のカギになると感じました。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOFF9BBlWzJbu63ukhPQH2D",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1TmPM8MR-I9IGMW16eSfK7LuqmVhu6FIg",
   "name": "Kaggle-BlackFriday.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
